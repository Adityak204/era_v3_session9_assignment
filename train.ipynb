{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Import PyTorch libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import multiprocessing\n",
    "\n",
    "# Import custom libraries\n",
    "from src.classifier import ResNet, Bottleneck\n",
    "from src.utils import train, test, seed_everything\n",
    "from src.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Instantiated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed_everything(42)\n",
    "\n",
    "resnet_model = ResNet(Bottleneck, [3, 4, 6, 3]).to(device)\n",
    "\n",
    "resnet_model_exp = copy.deepcopy(resnet_model)\n",
    "resnet_model_exp = nn.DataParallel(resnet_model_exp)\n",
    "resnet_model_exp = resnet_model_exp.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomResizedCrop(\n",
    "                224,\n",
    "                interpolation=transforms.InterpolationMode.BILINEAR,\n",
    "                antialias=True,\n",
    "            ),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            # Normalize the pixel values (in R, G, and B channels)\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.485, 0.406], std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=\"/home/ec2-user/ebs/volumes/imagenet/ILSVRC/Data/CLS-LOC/train\", \n",
    "    transform=train_transformation\n",
    ")\n",
    "train_sampler = torch.utils.data.RandomSampler(train_dataset)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=multiprocessing.cpu_count(),\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "optimizer = optim.SGD(resnet_model_exp.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "amp_config = {\n",
    "    'device_type': 'cuda',\n",
    "    'dtype': torch.float16,\n",
    "}\n",
    "grad_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "lr_finder = LRFinder(\n",
    "    model, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device='cuda',\n",
    "    amp_backend='torch', \n",
    "    amp_config=amp_config, \n",
    "    grad_scaler=grad_scaler\n",
    ")\n",
    "lr_finder.range_test(train_loader, end_lr=10, num_iter=100, step_mode='exp')\n",
    "lr_finder.plot()\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking number of cores available\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"train_path\" : \"/home/ec2-user/ebs/volumes/imagenet/ILSVRC/Data/CLS-LOC/train\",\n",
    "    \"val_path\" : \"/home/ec2-user/ebs/volumes/imagenet/imagenet_validation\",\n",
    "    \"batch_size\" : 128,\n",
    "    \"num_workers\" : multiprocessing.cpu_count(),\n",
    "    \"epochs\" : 2,\n",
    "    \"artifact_path\" : \"/home/ec2-user/ebs/volumes/era_session9\",\n",
    "}\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "seed_everything(42)\n",
    "\n",
    "optimizer = optim.SGD(resnet_model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"max\",\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    verbose=False,\n",
    "    threshold_mode='rel',\n",
    "    threshold=0.0001,\n",
    "    min_lr=1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Epoch = 1 *********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=6.7770 batch_id=436:   4%|‚ñç         | 437/10010 [08:54<3:15:17,  1.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m training \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mresnet_model,\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifact_path\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/era_v3/era_v3_session9_assignment/src/trainer.py:119\u001b[0m, in \u001b[0;36mTrainer.main\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m********* Epoch = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m *********\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 119\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     _, acc \u001b[38;5;241m=\u001b[39m test(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, val_loader)\n\u001b[1;32m    121\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(acc)\n",
      "File \u001b[0;32m~/era_v3/era_v3_session9_assignment/src/utils.py:33\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Compute accuracy\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# accumulate batch loss\u001b[39;00m\n\u001b[1;32m     34\u001b[0m _, pred \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39meq(target)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training = Trainer(\n",
    "    model=resnet_model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    train_path=config[\"train_path\"],\n",
    "    val_path=config[\"val_path\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    num_workers=config[\"num_workers\"],\n",
    "    epochs=config[\"epochs\"],\n",
    "    artifact_path=config[\"artifact_path\"],\n",
    ")\n",
    "training.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
